just_score_model: true
save_folder: /n/netscratch/sham_lab/Everyone/dclm/color_filter/scores/core-train-tasks/8b-reduced
max_duration: 75000 # ~520k tokens per step
global_train_batch_size: 256
device_train_microbatch_size: 256 
restore_dataloader: false # restart from step 0
reset_optimizer_state: true
reset_trainer_state: true
seed: 1
model:
  d_model: 768
  max_sequence_length: 2048
  mlp_hidden_size: 3072
  n_heads: 8
  n_layers: 12
  
sweep:
  - load_path:
      - prior
      - conditional_all
    load_checkpoint_type: unsharded
    data_start_step: # whole dataset in parallel
      - 0
      - 75000